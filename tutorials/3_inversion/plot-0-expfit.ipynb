{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "name": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.4.3",
      "pygments_lexer": "ipython3"
    }
  },
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSimple fit\n==========\n\nThis tutorial shows how to do the simplest inversion case, a curve fit, by\nsetting up an own forward operator. The function to be fitted is`\n\n\\begin{align}f(x) = A * e^{-x/X}\\end{align}\n\nwith the two unknown coefficients A (a signal  amplitude) and X (a decay rate).\nBoth A and X are assumed to be positive which is often the case for physical\nproperties. The easiest way to do this is via a logarithmic transformation of\nthe model vector (containing A and X) which is very easily done in pyGIMLi.\n\nFirst we import the pygimli library under a short name pg and the numerics\nlibrary numpy. Additionally we load the python plotting module of the library\nmatplotlib. Both are contained in most python distributions and systems.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "import pygimli as pg\nimport numpy as np\nimport matplotlib.pyplot as plt"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set up the modelling operator, i.e. to return ${\\bf f}({\\bf x})$ for\ngiven model parameters A and X subsumed in a vector. In order to be able to\nuse operator in inversion, we derive from the abstract modelling base class.\nThe latter holds the main mimic of generating Jacobian and adminstrating the\nmodel, the regularization and so on. The only function to overwrite is\n**response()**. If no function **createJacobian** is provided, they are\ncomputed by brute force (forward calculations with altered parameters).\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "class ExpModelling(pg.ModellingBase):\n    def __init__(self, xvec, verbose=False):\n        pg.ModellingBase.__init__(self, verbose)\n        self.x = xvec\n        self.setMesh(pg.createMesh1D(1, 2))\n        # self.regionManager().setParameterCount(2)\n\n    def response(self, model):\n        return model[0] * pg.exp(-self.x / model[1])\n\n    def startModel(self):\n        return [1.0, 0.3]"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The init function saves the x vector and defines the parameterization, i.e.\ntwo independent parameters (a 1D mesh with 1 cell and 2 properties).\nThe response function computes the function using A=model[0] and X=model[1]\nThe function startModel defines a meaningful starting vector. There are other\nmethods to set the starting model as inv.setModel() but this one is a default\none for people who use the class and forget about a starting model.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# We first create an abscissa vector using numpy (note that pygimli also\n# provides an exp function and generate synthetic data with two arbitrary A and\n# X values.\n\nx = np.arange(0, 1, 1e-2)\ndata = 10.5 * np.exp(- x / 550e-3)"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define an (absolute) error level and add Gaussian noise to the data.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "error = 0.1\ndata += np.random.randn(*data.shape)*error"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, an instance of the forward operator is created. We could use it for\ncalculating the synthetic data using f.response([10.5, 0.55]) or just\nf([10.5, 0.55]). We create a real-valued (R) inversion passing the forward\noperator, the data. A verbose boolean flag could be added to provide some\noutput the inversion, another one prints more and saves files for debugging.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f = ExpModelling(x)\ninv = pg.RInversion(data, f)"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a real-valued logarithmid transformation and appy it to the model.\nSimilar could be done for the data which are by default treated linearly.\nWe then set the error level that is used for data weighting. It can be a\nfloat number or a vector of data length. One can also set a relative error.\nFinally, we define the inversion style as Marquard scheme (pure local damping\nwith decreasing the regularization parameter subsequently) and start with a\nrelatively large regularization strength to avoid overshoot.\nFinally run yields the coefficient vector and we plot some statistics.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "tLog = pg.RTransLog()\ninv.setTransModel(tLog)\ninv.setAbsoluteError(error)\ninv.setMarquardtScheme()\ninv.setLambda(100)\ncoeff = inv.run()\ninv.echoStatus()  # result not shown on live docu\nprint(inv.absrms(), inv.relrms(), inv.chi2())\nprint(coeff)"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that after 5 iterations the absolute rms value equals the noise level\ncorresponding to a chi-squared misfit value of 1 as it should be the case for\nsynthetic data. The relative rms (in %) is less relevant here but can be for\nother applications. Additionally the ranges for model and model response are\ngiven and the objective function consisting of data misfit and model\nroughness times lambda. Note that due to the local regularization the second\nterm does not contribute to Phi. Set verbose to True to see the whole course\nof inversion. The values of the coefficient vector (a GIMLi real vector) are\nas expected close (i.e. equivalent) to the synthetic model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We finally create a plotting figure and plot both data and model response.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plt.figure()\nplt.plot(x, data, 'rx', x, inv.response(), 'b-')"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The createMesh1D automatically attributed the markers 0 and 1 to the two\nmodel parameters A and X, respectively. Each marker leads to a region that\ncan be individually treated, e.g. the starting value, lower or upper bounds,\nor all three at the same time (setParameters). This changes the model\ntransformation which can of course be region-specific.\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f.region(0).setLowerBound(0.1)\nf.region(0).setStartModel(3)\nf.region(1).setParameters(0.3, 0.01, 1.0)"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If these are set before the inversion is used, they are used automatically.\nWe set the model by hand using the new starting model\n\n"
      ]
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "inv.setVerbose(True)\ninv.setModel(f.createStartModel())\nprint(inv.run())\ninv.echoStatus()"
      ],
      "metadata": {
        "collapsed": false
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result is pretty much the same as before but for stronger equivalence or\nsmoothness-constrained regularization prior information might help a lot.\n\n"
      ]
    }
  ]
}